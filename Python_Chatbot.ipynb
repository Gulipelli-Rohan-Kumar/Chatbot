{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d8f0cf",
   "metadata": {},
   "source": [
    "# Chatbot in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726ef62",
   "metadata": {},
   "source": [
    "**Importing the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869c4731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/rohankumar/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cff31",
   "metadata": {},
   "source": [
    "**Importing and reading the corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dd714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rohankumar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rohankumar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "f=open('Chatbot.txt','r',errors = 'ignore')\n",
    "raw_doc=f.read()\n",
    "raw_doc=raw_doc.lower() #Converts text to lowercase\n",
    "nltk.download('punkt') #Using the Punkt tokenizer\n",
    "nltk.download('wordnet') #Using the WordNet dictionary\n",
    "sent_tokens = nltk.sent_tokenize(raw_doc) #Converts doc to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw_doc) #Converts doc to list of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2e76e",
   "metadata": {},
   "source": [
    "**Looking at a sentence token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3deb79f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science\\nfrom wikipedia, the free encyclopedia\\njump to navigationjump to search\\nnot to be confused with information science.',\n",
       " 'the existence of comet neowise (here depicted as a series of red dots) was discovered by analyzing astronomical survey data acquired by a space telescope, the wide-field infrared survey explorer.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c81a6",
   "metadata": {},
   "source": [
    "**Looking at a word token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c7ed83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'science']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9170aaa4",
   "metadata": {},
   "source": [
    "**Text Preprocessing. Pre-processing the raw text. We shall now define a function called LemTokens which will take as input the tokens and return normalized tokens.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3cd3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e8019",
   "metadata": {},
   "source": [
    "**Defining the Greet Function. If a user’s input is a greeting, the bot shall return a greeting response.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a013004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREET_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\")\n",
    "GREET_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "def greet(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREET_INPUTS:\n",
    "            return random.choice(GREET_RESPONSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c678e",
   "metadata": {},
   "source": [
    "**Response Generation. To generate a response from our bot for input questions, the concept of document similarity will be used. So we begin by importing the necessary modules.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e85d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287f0f2",
   "metadata": {},
   "source": [
    "**We define a function response that searches the user’s utterance for one or more general keywords and returns one of several possible responses. If it doesn’t find the input matching any of the keywords, it returns a response:” I am sorry! I don’t understand you.”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934da5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo1_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo1_response=robo1_response+\"I am sorry! I don't understand you\"\n",
    "        return robo1_response\n",
    "    else:\n",
    "        robo1_response = robo1_response+sent_tokens[idx]\n",
    "        return robo1_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb9725",
   "metadata": {},
   "source": [
    "**Defining conversation start/end protocols. Finally, we will feed the lines that we want our bot to say while starting and ending a conversation, depending upon the user’s input.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a3d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=True\n",
    "print(\"BOT: My name is Stark. Let's have a conversation! Also, if you want to exit any time, just type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"BOT: You are welcome..\")\n",
    "        else:\n",
    "            if(greet(user_response)!=None):\n",
    "                print(\"BOT: \"+greet(user_response))\n",
    "            else:\n",
    "                print(\"BOT: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"BOT: Goodbye! Take care <3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f85333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
